datasets:
  cifar100:
    name: &dataset_name 'cifar100'
    type: 'CIFAR100'
    root: &root_dir !join ['/home/qiuziming/data/', *dataset_name]
    splits:
      train:
        dataset_id: &cifar100_train !join [ *dataset_name, '/train' ]
        params:
          root: *root_dir
          train: True
          download: True
          transform_params:
            - type: 'RandomCrop'
              params:
                size: 32
                padding: 4
            - type: 'RandomHorizontalFlip'
              params:
                p: 0.5
            - type: 'ToTensor'
              params:
            - &normalize
              type: 'Normalize'
              params:
                mean: [ 0.5070754, 0.48655024, 0.44091907 ]
                std: [ 0.26733398, 0.25643876, 0.2761503 ]
      val:
        dataset_id: &cifar100_val !join [ *dataset_name, '/val' ]
        params:
          root: *root_dir
          train: False
          download: True
          transform_params: &val_transform
            - type: 'ToTensor'
              params:
            - *normalize
      test:
        dataset_id: &cifar100_test !join [*dataset_name, '/test']
        params:
          root: *root_dir
          train: False
          download: True
          transform_params: *val_transform

models:
  teacher_model:
    name: &teacher_model_name 'wide_resnet40_2'
    params:
      dropout_p: 0.0
      num_classes: 100
      pretrained: True
    experiment: &teacher_experiment !join [*dataset_name, '-', *teacher_model_name]
    ckpt: './resource/ckpt/icpkd/wrn_40_2_best.pth.tar'
  student_model:
    name: &student_model_name 'wide_resnet16_2'
    params:
      dropout_p: 0.0
      num_classes: &num_classes 100
      pretrained: False
    experiment: &student_experiment !join [*dataset_name, '-', *student_model_name, '_from_', *teacher_model_name]
    ckpt: !join ['./resource/ckpt/', *dataset_name, '/kd/', *student_experiment, '-final_run.pt']


train:
  log_freq: 100
  stage1:
    num_epochs: 1
    train_data_loader:
      dataset_id: *cifar100_train
      random_sample: True
      batch_size: 128
      num_workers: 4
      cache_output:
      dataset_wrapper:
        name: 'PolicyDatasetC100'
        params: {}
    val_data_loader:
      dataset_id: *cifar100_val
      random_sample: False
      batch_size: 256
      num_workers: 4
    teacher:
      forward_proc: 'forward_batch_target_policy'
      sequential: []
      special:
        type: 'WrapperPolicy'
        params:
          input_module: &teacherpolicy_in_module
            path: 'model.avgpool'
            io: 'output'
          identity: &identity False
          feat_dim: &teacherpolicy_feat_dim 128
          out_dim: &teacherpolicy_out_dim 128
          freezes_policy_module: False
          policy_module_ckpt: &teacherpolicy_ckpt !join ['/home/Bigdata/kd/policy/cifar10/', *student_experiment, '_teacher_policy_module.pt' ]
      forward_hook:
        input: []
        output: ['model.avgpool', 'policy_module']
      wrapper:
      requires_grad: True
      frozen_modules: ['model']
    student:
      adaptations:
      special:
        type: 'EmptyModule'
        params:
      sequential: []
      forward_hook:
        input: []
        output: []
      wrapper:
      requires_grad: False
    optimizer:
      type: 'SGD'
      params:
        lr: 0.1
        momentum: 0.9
        weight_decay: 0.0001
    scheduler:
      type: 'MultiStepLR'
      params:
        milestones: [ 10, 20 ]
        gamma: 0.1
    criterion:
      type: 'GeneralizedCustomLoss'
      org_term:
        factor: 0.0
      sub_terms:
        policy_loss:
          criterion:
            type: 'AuxPolicyKDLoss'
            params:
              ckpt_file_path:  &ckpt_file_path !join ['/home/Bigdata/kd/policy/cifar10/', *student_experiment, '_teacher_policy_linear_teacher.pt' ]
              module_path: 'policy_module'
              module_io: 'output'
              reduction: 'mean'
              feature_nums: &feature_nums 256
              policy_nums: &policy_nums 14
              negative_loss_weight: &negative_loss_weight [0.9,0.9,0.0]
              positive_loss_weight: &positive_loss_weight [0.3,0.7,0.0]
              num_classes: *num_classes
          factor: 1.0
  stage2:
    num_epochs: 240
    teacher:
      forward_proc: 'forward_batch_target_policy'
      sequential: []
      special:
        type: 'WrapperPolicy'
        params:
          input_module: *teacherpolicy_in_module
          feat_dim: *teacherpolicy_feat_dim
          out_dim: *teacherpolicy_out_dim
          freezes_policy_module: True
          policy_module_ckpt:  *teacherpolicy_ckpt
          use_ckpt: True
      forward_hook:
        input: []
        output: ['model.avgpool','model.fc','policy_module']
      wrapper:
      requires_grad: False
      frozen_modules: [ 'model' ]
    student:
      forward_proc: 'forward_batch_target_policy'
      special:
        type: 'WrapperPolicy'
        params:
          input_module: *teacherpolicy_in_module
          feat_dim: *teacherpolicy_feat_dim
          out_dim: *teacherpolicy_out_dim
          identity: *identity
          freezes_policy_module: True
          policy_module_ckpt: !join [ '/home/Bigdata/kd/policy/cifar10/', *student_experiment, '_teacher_policy_module.pt' ]
          use_ckpt: True
      adaptations:
      sequential: []
      forward_hook:
        input: []
        output: ['model.avgpool','model.fc','policy_module']
      wrapper:
      requires_grad: True
      frozen_modules: ['policy_module']
    apex:
      requires: False
      opt_level: '01'
    optimizer:
      type: 'SGD'
      params:
        lr: 0.1
        momentum: 0.9
        weight_decay: 0.0001
    scheduler:
      type: 'MultiStepLR'
      params:
        milestones: [150,180,210]
        gamma: 0.1
    criterion:
      type: 'GeneralizedCustomLoss'
      org_term:
        factor: 0.0
      sub_terms:
        policy_loss:
          criterion:
            type: 'PolicyLoss'
            params:
              ckpt_file_path: *ckpt_file_path
              student_linear_module_path: 'model.fc'
              teacher_linear_module_path: 'model.fc'
              student_policy_module_path: 'policy_module'
              teacher_policy_module_path: 'policy_module'
              kl_temp: 4.0
              policy_temp: 0.5
              policy_ratio: 0.75
              feature_nums: *feature_nums
              policy_nums: *policy_nums
              loss_weights: [ 1.0, 1.0, 0.0]
              p_t: 5
              option: 4
              negative_loss_weight: *negative_loss_weight
              positive_loss_weight: *positive_loss_weight
              kd_and_ce_weight: [0.0 , 0.0]
              reduction: 'batchmean'
              type: 'mse'
              num_classes: *num_classes
              freeze_student: False
          factor: 1.0
test:
  test_data_loader:
    dataset_id: *cifar100_test
    random_sample: False
    batch_size: 256
    num_workers: 4
