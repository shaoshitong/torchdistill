2022-04-17 20:18:28,252	INFO	torchdistill.common.main_util	Not using distributed mode
2022-04-17 20:18:28,252	INFO	__main__	Namespace(adjust_lr=False, config='configs/sample/cifar10/kd/resnet18_from_resnet50_sskd.yaml', device='cuda', dist_url='env://', log='log/cifar10/kd/resnet18_from_resnet50_sskd.txt', log_config=False, seed=None, start_epoch=0, student_only=False, test_only=False, world_size=1)
2022-04-17 20:18:28,288	INFO	torchdistill.datasets.util	Loading train data
2022-04-17 20:18:28,812	INFO	torchdistill.datasets.util	dataset_id `cifar10/train`: 0.5244553089141846 sec
2022-04-17 20:18:28,812	INFO	torchdistill.datasets.util	Loading val data
2022-04-17 20:18:29,225	INFO	torchdistill.datasets.util	dataset_id `cifar10/val`: 0.41311168670654297 sec
2022-04-17 20:18:29,225	INFO	torchdistill.datasets.util	Loading test data
2022-04-17 20:18:29,637	INFO	torchdistill.datasets.util	dataset_id `cifar10/test`: 0.41141200065612793 sec
2022-04-17 20:18:29,683	INFO	torchdistill.common.main_util	ckpt file is not found at `/home/Bigdta/kd/laji/ckpt/cifar10/teacher/cifar10-resnet56.pt`
2022-04-17 20:18:32,203	INFO	torchdistill.common.main_util	ckpt file is not found at `/home/Bigdta/kd/laji/ckpt/cifar10/kd/cifar10-resnet20_from_resnet56-final_run.pt`
2022-04-17 20:18:32,205	INFO	__main__	Start training
2022-04-17 20:18:32,205	INFO	torchdistill.models.util	[teacher model]
2022-04-17 20:18:32,205	INFO	torchdistill.models.util	Using the SSWrapper4SSKD teacher model
2022-04-17 20:18:32,205	INFO	torchdistill.models.util	Frozen module(s): {'model'}
2022-04-17 20:18:32,206	INFO	torchdistill.models.util	[student model]
2022-04-17 20:18:32,206	INFO	torchdistill.models.util	Using the EmptyModule student model
2022-04-17 20:18:32,206	INFO	torchdistill.core.distillation	Loss = 1.0 * AuxSSKDLoss()
2022-04-17 20:18:32,206	INFO	torchdistill.core.distillation	Freezing the whole student model
2022-04-17 20:18:32,207	INFO	torchdistill.core.distillation	Note that you are training some/all of the modules in the teacher model
2022-04-17 20:18:32,207	INFO	torchdistill.core.distillation	Started stage 1
2022-04-17 20:18:32,906	INFO	torchdistill.misc.log	Epoch: [0]  [  0/782]  eta: 0:09:05  lr: 0.1  img/s: 864.2564351877191  loss: 4.0248 (4.0248)  time: 0.6978  data: 0.6236  max mem: 185
2022-04-17 20:18:33,937	INFO	torchdistill.misc.log	Epoch: [0]  [100/782]  eta: 0:00:11  lr: 0.1  img/s: 6543.056988251353  loss: 3.5841 (3.6303)  time: 0.0101  data: 0.0001  max mem: 185
2022-04-17 20:18:34,948	INFO	torchdistill.misc.log	Epoch: [0]  [200/782]  eta: 0:00:07  lr: 0.1  img/s: 6448.590001681601  loss: 3.5422 (3.5954)  time: 0.0101  data: 0.0001  max mem: 185
2022-04-17 20:18:35,967	INFO	torchdistill.misc.log	Epoch: [0]  [300/782]  eta: 0:00:06  lr: 0.1  img/s: 6410.552037063571  loss: 3.5263 (3.5752)  time: 0.0102  data: 0.0001  max mem: 185
2022-04-17 20:18:36,992	INFO	torchdistill.misc.log	Epoch: [0]  [400/782]  eta: 0:00:04  lr: 0.1  img/s: 6508.6307009674365  loss: 3.5272 (3.5635)  time: 0.0103  data: 0.0001  max mem: 185
2022-04-17 20:18:38,011	INFO	torchdistill.misc.log	Epoch: [0]  [500/782]  eta: 0:00:03  lr: 0.1  img/s: 5938.968915241488  loss: 3.5034 (3.5539)  time: 0.0102  data: 0.0001  max mem: 185
2022-04-17 20:18:39,035	INFO	torchdistill.misc.log	Epoch: [0]  [600/782]  eta: 0:00:02  lr: 0.1  img/s: 6192.139881432954  loss: 3.5028 (3.5462)  time: 0.0102  data: 0.0001  max mem: 185
2022-04-17 20:18:40,057	INFO	torchdistill.misc.log	Epoch: [0]  [700/782]  eta: 0:00:00  lr: 0.1  img/s: 6230.369177207845  loss: 3.4989 (3.5400)  time: 0.0102  data: 0.0001  max mem: 185
2022-04-17 20:18:40,944	INFO	torchdistill.misc.log	Epoch: [0] Total time: 0:00:08
2022-04-17 20:18:41,395	INFO	torchdistill.misc.log	Validation:  [ 0/79]  eta: 0:00:35  acc1: 14.8438 (14.8438)  acc5: 58.5938 (58.5938)  time: 0.4496  data: 0.4270  max mem: 185
2022-04-17 20:18:41,687	INFO	torchdistill.misc.log	Validation: Total time: 0:00:00
2022-04-17 20:18:41,688	INFO	__main__	 * Acc@1 10.0000	Acc@5 50.0000

2022-04-17 20:18:41,688	INFO	__main__	Best top-1 accuracy: 0.0000 -> 10.0000
2022-04-17 20:18:41,688	INFO	__main__	Updating ckpt at /home/Bigdta/kd/laji/ckpt/cifar10/kd/cifar10-resnet20_from_resnet56-final_run.pt
2022-04-17 20:18:42,209	INFO	torchdistill.misc.log	Epoch: [1]  [  0/782]  eta: 0:06:42  lr: 0.1  img/s: 4587.699207000273  loss: 3.5181 (3.5181)  time: 0.5142  data: 0.5001  max mem: 185
2022-04-17 20:18:43,244	INFO	torchdistill.misc.log	Epoch: [1]  [100/782]  eta: 0:00:10  lr: 0.1  img/s: 6504.372570874727  loss: 3.4869 (3.4968)  time: 0.0103  data: 0.0001  max mem: 185
2022-04-17 20:18:44,271	INFO	torchdistill.misc.log	Epoch: [1]  [200/782]  eta: 0:00:07  lr: 0.1  img/s: 6486.141593775673  loss: 3.4818 (3.4966)  time: 0.0102  data: 0.0001  max mem: 185
2022-04-17 20:18:45,300	INFO	torchdistill.misc.log	Epoch: [1]  [300/782]  eta: 0:00:05  lr: 0.1  img/s: 6546.886883566655  loss: 3.4929 (3.4940)  time: 0.0102  data: 0.0001  max mem: 185
2022-04-17 20:18:46,328	INFO	torchdistill.misc.log	Epoch: [1]  [400/782]  eta: 0:00:04  lr: 0.1  img/s: 6258.257897559042  loss: 3.4976 (3.4935)  time: 0.0103  data: 0.0001  max mem: 185
2022-04-17 20:18:47,382	INFO	torchdistill.misc.log	Epoch: [1]  [500/782]  eta: 0:00:03  lr: 0.1  img/s: 6491.474559876185  loss: 3.4745 (3.4925)  time: 0.0104  data: 0.0001  max mem: 185
2022-04-17 20:18:48,460	INFO	torchdistill.misc.log	Epoch: [1]  [600/782]  eta: 0:00:02  lr: 0.1  img/s: 6563.535038388185  loss: 3.4911 (3.4919)  time: 0.0102  data: 0.0001  max mem: 185
2022-04-17 20:18:49,499	INFO	torchdistill.misc.log	Epoch: [1]  [700/782]  eta: 0:00:00  lr: 0.1  img/s: 6011.5883815197185  loss: 3.4834 (3.4907)  time: 0.0104  data: 0.0001  max mem: 185
2022-04-17 20:18:50,407	INFO	torchdistill.misc.log	Epoch: [1] Total time: 0:00:08
2022-04-17 20:18:50,867	INFO	torchdistill.misc.log	Validation:  [ 0/79]  eta: 0:00:36  acc1: 14.8438 (14.8438)  acc5: 58.5938 (58.5938)  time: 0.4582  data: 0.4536  max mem: 185
2022-04-17 20:18:51,158	INFO	torchdistill.misc.log	Validation: Total time: 0:00:00
2022-04-17 20:18:51,159	INFO	__main__	 * Acc@1 10.0000	Acc@5 50.0000

2022-04-17 20:18:51,657	INFO	torchdistill.misc.log	Epoch: [2]  [  0/782]  eta: 0:06:28  lr: 0.1  img/s: 4614.116506523196  loss: 3.5062 (3.5062)  time: 0.4964  data: 0.4824  max mem: 185
2022-04-17 20:18:52,733	INFO	torchdistill.misc.log	Epoch: [2]  [100/782]  eta: 0:00:10  lr: 0.1  img/s: 6171.0718867100395  loss: 3.4747 (3.4848)  time: 0.0106  data: 0.0001  max mem: 185
2022-04-17 20:18:53,830	INFO	torchdistill.misc.log	Epoch: [2]  [200/782]  eta: 0:00:07  lr: 0.1  img/s: 6463.184840969831  loss: 3.4794 (3.4858)  time: 0.0104  data: 0.0001  max mem: 185
2022-04-17 20:18:54,854	INFO	torchdistill.misc.log	Epoch: [2]  [300/782]  eta: 0:00:05  lr: 0.1  img/s: 6308.558106742497  loss: 3.4818 (3.4853)  time: 0.0103  data: 0.0001  max mem: 185
2022-04-17 20:18:55,886	INFO	torchdistill.misc.log	Epoch: [2]  [400/782]  eta: 0:00:04  lr: 0.1  img/s: 6497.130796785749  loss: 3.4681 (3.4841)  time: 0.0103  data: 0.0001  max mem: 185
2022-04-17 20:18:56,917	INFO	torchdistill.misc.log	Epoch: [2]  [500/782]  eta: 0:00:03  lr: 0.1  img/s: 6352.750112412732  loss: 3.4700 (3.4827)  time: 0.0101  data: 0.0001  max mem: 185
